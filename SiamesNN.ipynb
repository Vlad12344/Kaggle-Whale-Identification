{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zaA0wkJlBwIF",
    "outputId": "ab101b37-229b-42d5-8586-a10d6250458e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlados/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.applications import Xception\n",
    "from keras.layers import Input, merge, SeparableConv2D, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense,Input, Flatten\n",
    "from keras.layers import Activation, Dense, Dropout, Lambda, GlobalMaxPooling2D, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from scipy.misc import imresize\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras import activations\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import regularizers\n",
    "from keras import layers\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-reStX7rnpiS"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/media/vlados/FreeSpace/Kaggle/Humpback\"\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, \"siames dataset\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test_dataset_2', 'test')\n",
    "\n",
    "WIDTH = 299\n",
    "HEIGHT = 299\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SJP42A1ysGXT",
    "outputId": "098fd803-c534-4447-8c64-d44fbcdb5729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 66912 pos + 66912 neg = 133824 total image triples, COMPLETE\n"
     ]
    }
   ],
   "source": [
    "image_groups = {}\n",
    "\n",
    "for image_name in os.listdir(IMAGE_DIR):\n",
    "    base_name = image_name[0:-4]\n",
    "    group_name = base_name[0:4]\n",
    "    \n",
    "    if group_name in image_groups:\n",
    "        image_groups[group_name].append(image_name)\n",
    "    else:\n",
    "        image_groups[group_name] = [image_name]\n",
    "\n",
    "num_sim = 0\n",
    "image_triples = []\n",
    "group_list = sorted(list(image_groups.keys()))\n",
    "\n",
    "for i, g in enumerate(group_list):\n",
    "    if num_sim % 100 == 0:\n",
    "        print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "              .format(num_sim, num_sim, 2*num_sim), end=\"\\r\")\n",
    "    images_in_group = image_groups[g]\n",
    "\n",
    "    # generate similar pairs\n",
    "    sim_pairs_it = itertools.combinations(images_in_group, 2)\n",
    "    \n",
    "    # for each similar pair, generate a different pair\n",
    "    \n",
    "    for ref_image, sim_image in sim_pairs_it:\n",
    "        image_triples.append((ref_image, sim_image, 1))\n",
    "        num_sim += 1\n",
    "        \n",
    "        while True:\n",
    "            j = np.random.randint(low=0, high=len(group_list), size=1)[0]\n",
    "            if j != i: break\n",
    "        \n",
    "        dif_image_candidates = image_groups[group_list[j]]\n",
    "        k = np.random.randint(low=0, high=len(dif_image_candidates), size=1)[0]\n",
    "        dif_image = dif_image_candidates[k]\n",
    "        image_triples.append((ref_image, dif_image, 0))\n",
    "        \n",
    "print(\"Generated {:d} pos + {:d} neg = {:d} total image triples, COMPLETE\"\n",
    "      .format(num_sim, num_sim, 2*num_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sL0zIxXbB1L1"
   },
   "outputs": [],
   "source": [
    "split_point = int(len(image_triples) * 0.8)\n",
    "triples_train, triples_test = image_triples[0:split_point], image_triples[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfnASYdfD0j7"
   },
   "outputs": [],
   "source": [
    "def cached_imread(image_path, image_cache, img_size):\n",
    "    \n",
    "    if image_path not in image_cache:\n",
    "        image = plt.imread(image_path)\n",
    "        image = cv2.resize(image, (img_size, img_size))\n",
    "        image_cache[image_path] = image    \n",
    "    \n",
    "    return image_cache[image_path]\n",
    "\n",
    "def preprocess_images(image_names, seed, datagen, image_cache, img_size=299):\n",
    "    np.random.seed(seed)\n",
    "    X = np.zeros((len(image_names), WIDTH, HEIGHT, 3))\n",
    "    \n",
    "    for i, image_name in enumerate(image_names):\n",
    "        image = cached_imread(os.path.join(IMAGE_DIR, image_name), image_cache, img_size)\n",
    "        X[i] = datagen.random_transform(image)\n",
    "\n",
    "    return X\n",
    "\n",
    "def image_triple_generator(image_triples, batch_size, size):\n",
    "    \n",
    "    datagen_args = dict(rotation_range=10,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        preprocessing_function=preprocess_input)\n",
    "    \n",
    "    datagen_left = ImageDataGenerator(**datagen_args)\n",
    "    datagen_right = ImageDataGenerator(**datagen_args)\n",
    "    image_cache = {}\n",
    "    \n",
    "    while True:\n",
    "        # loop once per epoch\n",
    "        num_recs = len(image_triples)\n",
    "        indices = np.random.permutation(np.arange(num_recs))\n",
    "        num_batches = num_recs // batch_size\n",
    "        \n",
    "        for bid in range(num_batches):\n",
    "            # loop once per batch\n",
    "            batch_indices = indices[bid * batch_size : (bid + 1) * batch_size]\n",
    "            batch = [image_triples[i] for i in batch_indices]\n",
    "            \n",
    "            # make sure image data generators generate same transformations\n",
    "            seed = np.random.randint(low=0, high=1000, size=1)[0]\n",
    "            \n",
    "            Xleft = preprocess_images([b[0] for b in batch], seed, \n",
    "                                      datagen_left, image_cache, img_size=size)\n",
    "            \n",
    "            Xright = preprocess_images([b[1] for b in batch], seed,\n",
    "                                       datagen_right, image_cache, img_size=size)\n",
    "            \n",
    "#             Y = np_utils.to_categorical(np.array([b[2] for b in batch]))\n",
    "            Y = np.array([b[2] for b in batch])\n",
    "        \n",
    "            \n",
    "            yield ([Xleft, Xright], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DiMHbmQMpa7U",
    "outputId": "177f80bc-966f-4d9a-9a42-e2eb16420761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 299, 299, 3) (8, 299, 299, 3) [0 0 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "triples_batch_gen = image_triple_generator(image_triples, 8, WIDTH)\n",
    "[Xleft, Xright], Y = next(triples_batch_gen)\n",
    "print(Xleft.shape, Xright.shape, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDe5guLpDtJ9"
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    xception = Xception(weights='imagenet', \n",
    "                         include_top=True, \n",
    "                         input_shape=input_shape)\n",
    "     \n",
    "    model = Model(input=xception.input,\n",
    "                 output=xception.get_layer(\"avg_pool\").output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def cosine_distance(vecs, normalize=False):\n",
    "    x, y = vecs\n",
    "    if normalize:\n",
    "        x = K.l2_normalize(x, axis=0)\n",
    "        y = K.l2_normalize(x, axis=0)\n",
    "    return K.prod(K.stack([x, y], axis=1), axis=1)\n",
    "\n",
    "def cosine_distance_output_shape(shapes):\n",
    "    return shapes[0]\n",
    "\n",
    "def compute_accuracy(preds, labels):\n",
    "    return labels[preds.ravel() < 0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2euUrPuGh6Xs"
   },
   "outputs": [],
   "source": [
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "XWprOTMYZ1Nn",
    "outputId": "0541afad-6aff-4737-ec21-65db718a97f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlados/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"av...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "input_shape = (299, 299, 3)\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "image_left = Input(shape=input_shape)\n",
    "image_right = Input(shape=input_shape)\n",
    "\n",
    "vector_left = base_network(image_left)\n",
    "vector_right = base_network(image_right)\n",
    "\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "L1_distance = L1_layer([vector_left, vector_right])\n",
    "    \n",
    "# Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "prediction = Dense(1,activation='sigmoid', bias_initializer=initialize_bias)(L1_distance)\n",
    "\n",
    "x_corr_mod = Model(inputs=[image_left, image_right], outputs=prediction)\n",
    "\n",
    "x_corr_mod.load_weights(os.path.join(DATA_DIR, '02-085.h5py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "SQ3rVrbYtESx",
    "outputId": "371034fb-5400-4463-ba55-47699ad5e345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 2048)         20861480    input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2048)         0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2049        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_corr_mod.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "x_corr_mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "EgwPmxQVwgFw",
    "outputId": "f019f7fc-c637-4c97-99ab-9e1df0d83631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7647/7647 [==============================] - 21131s 3s/step - loss: 0.4792 - acc: 0.7688 - val_loss: 0.4050 - val_acc: 0.8241\n",
      "Epoch 2/2\n",
      "7647/7647 [==============================] - 17966s 2s/step - loss: 0.3238 - acc: 0.8659 - val_loss: 0.3622 - val_acc: 0.8499\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 14\n",
    "\n",
    "filepath = os.path.join(DATA_DIR, \"{epoch:02d}-{val_acc:.2f}.h5py\")\n",
    "\n",
    "callback = ModelCheckpoint(filepath, save_best_only=False, save_weights_only=False, period=1)\n",
    "\n",
    "image_cache = {}\n",
    "train_gen = image_triple_generator(triples_train, BATCH_SIZE, WIDTH)\n",
    "val_gen = image_triple_generator(triples_test, BATCH_SIZE, WIDTH)\n",
    "\n",
    "num_train_steps = len(triples_train) // BATCH_SIZE\n",
    "num_val_steps = len(triples_test) // BATCH_SIZE\n",
    "\n",
    "history = x_corr_mod.fit_generator(train_gen,\n",
    "                              steps_per_epoch=num_train_steps,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=num_val_steps,\n",
    "                              callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IxMsqWcCwkZO",
    "outputId": "a81aa0a2-2103-48f5-ac4f-8c4eac2ea575"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e0b62f93b84387a1023d0f2ef4b956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15222), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26a069503834629beedfcb2f57df252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7960), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_imges_path = []\n",
    "test_imges_path = []\n",
    "\n",
    "for path in tqdm_notebook(sorted(os.listdir(IMAGE_DIR))):\n",
    "    train_imges_path.append(os.path.join(IMAGE_DIR, path))\n",
    "for path in tqdm_notebook(sorted(os.listdir(TEST_DIR))):\n",
    "    test_imges_path.append(os.path.join(TEST_DIR, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_imges_path):    \n",
    "    dataset = np.zeros(len(train_imges_path))\n",
    "    \n",
    "    for i, path in tqdm_notebook(enumerate(train_imges_path)):\n",
    "        dataset[i] = cv2.imread(path)\n",
    "        \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(path2img, size=299):\n",
    "    img = cv2.imread(path2img)\n",
    "    img = cv2.resize(img, (size, size))\n",
    "#     img = test_img.astype(np.float32)\n",
    "#     img = preprocess_input(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch):\n",
    "    while True:\n",
    "    \n",
    "        left_part = np.zeros((batch, 299, 299, 3))\n",
    "        right_part = np.zeros((batch, 299, 299, 3))\n",
    "        \n",
    "        for i, path in enumerate(test_imges_path):\n",
    "            left_part[:,:,:,:] = preprocess_img(path)\n",
    "            \n",
    "            for j in range(len(train_imges_path)//batch):\n",
    "                chunk = train_imges_path[j*batch : (j+1)*batch]\n",
    "                \n",
    "                for k, path in enumerate(chunk):\n",
    "                    right_part[k] = preprocess_img(path)\n",
    "        \n",
    "                yield [left_part, right_part]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff728320fd0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(next(batch_generator(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2203
    },
    "colab_type": "code",
    "id": "tiNWDnYjIm9t",
    "outputId": "ac018036-5a59-4403-b123-3a8a88ded140"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlados/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:2487: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/managers.py\", line 756, in _callmethod\n",
      "    conn.send((self._id, methodname, args, kwds))\n",
      "  File \"<string>\", line 2, in put\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 678, in _data_generator_task\n",
      "    self.queue.put((True, generator_output))\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/home/vlados/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-a60e2716b555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                            workers=5, use_multiprocessing=True, verbose=1)[:,0]\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-a60e2716b555>\u001b[0m in \u001b[0;36mmodel_testing\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     predict = x_corr_mod.predict_generator(batch_generator(batch), max_queue_size=10, steps=1000,\n\u001b[0;32m----> 3\u001b[0;31m                                            workers=5, use_multiprocessing=True, verbose=1)[:,0]\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2538\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2540\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2541\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1943\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1312\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             tf_session.TF_ExtendGraph(self._session,\n\u001b[0;32m-> 1358\u001b[0;31m                                       graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1359\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def model_testing(batch):\n",
    "    predict = x_corr_mod.predict_generator(batch_generator(batch), max_queue_size=10, steps=1000,\n",
    "                                           workers=5, use_multiprocessing=True, verbose=1)[:,0]\n",
    "            \n",
    "model_testing(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
