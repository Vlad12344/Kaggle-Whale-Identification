{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "from skimage import measure \n",
    "\n",
    "def create_sub_masks(mask_image):\n",
    "    width, height = mask_image.size\n",
    "\n",
    "    # Initialize a dictionary of sub-masks indexed by RGB colors\n",
    "    sub_masks = {}\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # Get the RGB values of the pixel\n",
    "            pixel = mask_image.getpixel((x,y))\n",
    "\n",
    "            # If the pixel is not black...\n",
    "            if pixel != (0):\n",
    "                # Check to see if we've created a sub-mask...\n",
    "                pixel_str = str(pixel)\n",
    "                sub_mask = sub_masks.get(pixel_str)\n",
    "                if sub_mask is None:\n",
    "                   # Create a sub-mask (one bit per pixel) and add to the dictionary\n",
    "                    # Note: we add 1 pixel of padding in each direction\n",
    "                    # because the contours module doesn't handle cases\n",
    "                    # where pixels bleed to the edge of the image\n",
    "                    sub_masks[pixel_str] = Image.new('1', (width+2, height+2))\n",
    "\n",
    "                # Set the pixel value to 1 (default is 0), accounting for padding\n",
    "                sub_masks[pixel_str].putpixel((x+1, y+1), 1)\n",
    "\n",
    "    return sub_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, MultiPolygon # (pip install Shapely)\n",
    "\n",
    "def create_sub_mask_annotation(image_name, sub_mask, image_id, category_id, annotation_id, is_crowd):\n",
    "    # Find contours (boundary lines) around each sub-mask\n",
    "    # Note: there could be multiple contours if the object\n",
    "    # is partially occluded. (E.g. an elephant behind a tree)\n",
    "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
    "    \n",
    "    segmentations = []\n",
    "    polygons = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Flip from (row, col) representation to (x, y)\n",
    "        # and subtract the padding pixel\n",
    "        for i in range(len(contour)):\n",
    "            row, col = contour[i]\n",
    "            contour[i] = (col - 1, row - 1)\n",
    "\n",
    "        # Make a polygon and simplify it\n",
    "        poly = Polygon(contour)\n",
    "        \n",
    "        poly = poly.simplify(1.0, preserve_topology=False)\n",
    "        polygons.append(poly)\n",
    "        segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
    "        segmentations.append(segmentation)\n",
    "        \n",
    "    # Combine the polygons to calculate the bounding box and area\n",
    "    multi_poly = MultiPolygon(polygons)\n",
    "    x, y, max_x, max_y = multi_poly.bounds\n",
    "    width = max_x - x\n",
    "    height = max_y - y\n",
    "    bbox = (x, y, width, height)\n",
    "    area = multi_poly.area\n",
    "\n",
    "    annotation = {\n",
    "        'segmentation': segmentations,\n",
    "        'iscrowd': is_crowd,\n",
    "        'image_id': image_id,\n",
    "        'category_id': category_id,\n",
    "        'id': annotation_id,\n",
    "        'bbox': bbox,\n",
    "        'area': area\n",
    "    }\n",
    "    \n",
    "    image = {\n",
    "        'licence': 0,\n",
    "        'file_name': image_name,\n",
    "        'width': sub_mask.size[0] - 2,\n",
    "        'height': sub_mask.size[1] - 2,\n",
    "        'id': annotation_id\n",
    "    }\n",
    "\n",
    "    return annotation, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [14:30<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_dir = '/home/vlados/Documents/Mask_RCNN/generated/train'\n",
    "masks_names = sorted(os.listdir(os.path.join(dataset_dir, 'masks')))\n",
    "images_names = sorted(os.listdir(os.path.join(dataset_dir, 'images')))\n",
    "\n",
    "# Define which colors match which categories in the images\n",
    "tail_id = 1\n",
    "\n",
    "category_ids = { 1: {'255': tail_id} }\n",
    "category_id = 1\n",
    "# These ids will be automatically increased as we go\n",
    "image_id = 0\n",
    "is_crowd = 0\n",
    "annotation_id = 0\n",
    "\n",
    "# Create the annotations\n",
    "images = []\n",
    "annotations = []\n",
    "\n",
    "for i in tqdm(range(len(masks_names))):\n",
    "    tail_mask = Image.open(os.path.join(dataset_dir, 'masks', masks_names[i]))\n",
    "    sub_masks = create_sub_masks(tail_mask)\n",
    "    for color, sub_mask in sub_masks.items():\n",
    "        #category_id = category_ids[image_id][color]\n",
    "        annotation, image = create_sub_mask_annotation(images_names[i], sub_mask, image_id, \n",
    "                                                category_id, annotation_id, is_crowd)\n",
    "        images.append(image)\n",
    "        annotations.append(annotation)\n",
    "        annotation_id += 1\n",
    "    image_id += 1\n",
    "\n",
    "supercategory = [{\"supercategory\": \"humpback\", \"id\": 1, \"name\": \"teils\"}]\n",
    "\n",
    "with open('/home/vlados/Documents/Mask_RCNN/coco_annotations.json', 'w') as outfile:\n",
    "    json.dump({'images': images, 'annotations': annotations, 'categories': supercategory}, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
